{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2770b30b-b382-4821-b216-71434c8fb873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "BASE_DIR = os.path.abspath(os.path.join('..'))  # je≈õli notebook w Strategies/notebook\n",
    "sys.path.append(BASE_DIR)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import MetaTrader5 as mt5\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import config\n",
    "\n",
    "def get_live_data(symbol, timeframe, candle_lookback):\n",
    "\n",
    "    if not mt5.initialize():\n",
    "        raise RuntimeError(f\"MT5 initialize failed: {mt5.last_error()}\")\n",
    "\n",
    "    if not mt5.symbol_select(symbol, True):\n",
    "        mt5.symbol_select(symbol, False)  # Deselect\n",
    "        time.sleep(0.5)\n",
    "        if not mt5.symbol_select(symbol, True):\n",
    "            raise RuntimeError(f\"Still can't select symbol: {symbol}\")\n",
    "\n",
    "    rates = mt5.copy_rates_from_pos(symbol, timeframe, 0, candle_lookback)\n",
    "\n",
    "    if rates is None or len(rates) == 0:\n",
    "        raise ValueError(\"Brak danych dla podanego zakresu dat.\")\n",
    "\n",
    "    df = pd.DataFrame(rates)\n",
    "\n",
    "    df['time'] = pd.to_datetime(df['time'], unit='s', utc=True)\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "def pandas_freq_from_timeframe(tf: str) -> str:\n",
    "    mapping = {\n",
    "        'H1': '1h',\n",
    "        'H4': '4h',\n",
    "        'D1': '1d',\n",
    "        'M1': '1min',\n",
    "        'M5': '5min',\n",
    "        'M15': '15min',\n",
    "    }\n",
    "    return mapping.get(tf.upper(), tf)\n",
    "\n",
    "def get_data(symbol, timeframe, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Pobiera dane z MetaTrader 5 dla wybranego symbolu i przedzia≈Çu czasowego.\n",
    "\n",
    "    Args:\n",
    "        symbol (str): np. 'EURUSD'\n",
    "        timeframe (mt5.TIMEFRAME_*): np. mt5.TIMEFRAME_H1\n",
    "        start_date (datetime): data poczƒÖtkowa\n",
    "        end_date (datetime): data ko≈Ñcowa\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: dane OHLC + wolumen z datami\n",
    "    \"\"\"\n",
    "    # Inicjalizacja\n",
    "    if not mt5.initialize():\n",
    "        raise RuntimeError(f\"MT5 initialize failed: {mt5.last_error()}\")\n",
    "\n",
    "    # Pr√≥ba w≈ÇƒÖczenia symbolu\n",
    "    if not mt5.symbol_select(symbol, True):\n",
    "        time.sleep(0.5)\n",
    "        if not mt5.symbol_select(symbol, True):\n",
    "            mt5.shutdown()\n",
    "            raise RuntimeError(f\"Nie mo≈ºna wybraƒá symbolu: {symbol}\")\n",
    "\n",
    "    # Pobranie danych\n",
    "    rates = mt5.copy_rates_range(symbol, timeframe, start_date, end_date)\n",
    "    if rates is None or len(rates) == 0:\n",
    "        mt5.shutdown()\n",
    "        raise ValueError(f\"Brak danych dla {symbol} w podanym zakresie dat.\")\n",
    "\n",
    "    # Konwersja do DataFrame\n",
    "    df = pd.DataFrame(rates)\n",
    "    df['time'] = pd.to_datetime(df['time'], unit='s')\n",
    "    df = df[['time', 'open', 'high', 'low', 'close', 'tick_volume']]\n",
    "\n",
    "    # Zako≈Ñczenie po≈ÇƒÖczenia\n",
    "    mt5.shutdown()\n",
    "\n",
    "    return df\n",
    "\n",
    "def merge_informative_data(df: pd.DataFrame, timeframe: str, informative_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    freq = pandas_freq_from_timeframe(timeframe)\n",
    "    time_col = f'time_{timeframe}'\n",
    "\n",
    "    #print(f\"[merge_informative_data] Before timezone fix, df['time'] sample: {df['time'].head(3).tolist()}\")\n",
    "    if df['time'].dt.tz is None:\n",
    "        #print(\"[merge_informative_data] df['time'] is tz-naive, localizing...\")\n",
    "        df['time'] = df['time'].dt.tz_localize(config.SERVER_TIMEZONE)\n",
    "    else:\n",
    "        #print(f\"[merge_informative_data] df['time'] is tz-aware with tz: {df['time'].dt.tz}, converting...\")\n",
    "        df['time'] = df['time'].dt.tz_convert(config.SERVER_TIMEZONE)\n",
    "    #print(f\"[merge_informative_data] After fix, df['time'] sample: {df['time'].head(3).tolist()}\")\n",
    "\n",
    "    df[time_col] = df['time'].dt.tz_convert(config.SERVER_TIMEZONE).dt.floor(freq)\n",
    "    #print(f\"[merge_informative_data] Created column '{time_col}' sample: {df[time_col].head(3).tolist()}\")\n",
    "\n",
    "\n",
    "    informative_df = informative_df.rename(columns={\n",
    "        col: f\"{col}_{timeframe}\" for col in informative_df.columns if col != 'time'\n",
    "    })\n",
    "\n",
    "    merged = df.merge(\n",
    "        informative_df,\n",
    "        left_on=time_col,\n",
    "        right_on='time',\n",
    "        how='left'\n",
    "    )\n",
    "    #print(f\"[merge_informative_data] Merged dataframe length: {len(merged)}\")\n",
    "\n",
    "    return merged.drop(columns=['time'], errors='ignore')\n",
    "\n",
    "\n",
    "\n",
    "data = get_data(\"EURUSD\", mt5.TIMEFRAME_M5, datetime(2025,1,1), datetime(2025,10,20))\n",
    "data_H1 = get_data(\"EURUSD\", mt5.TIMEFRAME_H1, datetime(2025,1,1), datetime(2025,10,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6077d62b-63f8-4e11-9d85-192c5f6b025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.decorators import informative\n",
    "from TechnicalAnalysis.Indicators import indicators as qtpylib\n",
    "from TechnicalAnalysis.PointOfInterestSMC.core import SmartMoneyConcepts\n",
    "from TechnicalAnalysis.SessionsSMC.core import SessionsSMC\n",
    "\n",
    "import talib.abstract as ta\n",
    "\n",
    "def get_informative_dataframe(symbol, timeframe: str, startup_candle_count: int) -> pd.DataFrame:\n",
    "    freq = pandas_freq_from_timeframe(timeframe)\n",
    "    tf_minutes = pd.to_timedelta(freq).total_seconds() / 60\n",
    "    extra_minutes = tf_minutes * startup_candle_count\n",
    "\n",
    "    start_time = pd.to_datetime(config.TIMERANGE['start']).tz_localize(config.SERVER_TIMEZONE) - pd.to_timedelta(extra_minutes, unit='m')\n",
    "    end_time = pd.to_datetime(config.TIMERANGE['end']).tz_localize(config.SERVER_TIMEZONE)\n",
    "\n",
    "\n",
    "\n",
    "    df = get_live_data(\n",
    "        symbol,\n",
    "        getattr(mt5, f\"TIMEFRAME_{timeframe}\"),\n",
    "        6000\n",
    "    )\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "def populate_informative_indicators(obj_with_df_and_symbol):\n",
    "    for attr_name in dir(obj_with_df_and_symbol):\n",
    "        attr = getattr(obj_with_df_and_symbol, attr_name)\n",
    "        if callable(attr) and getattr(attr, '_informative', False):\n",
    "            timeframe = attr._informative_timeframe\n",
    "            if timeframe not in obj_with_df_and_symbol.informative_dataframes:\n",
    "                informative_df = get_informative_dataframe(\n",
    "                    symbol=obj_with_df_and_symbol.symbol,\n",
    "                    timeframe=timeframe,\n",
    "                    startup_candle_count=obj_with_df_and_symbol.startup_candle_count\n",
    "                )\n",
    "                informative_df = attr(df=informative_df.copy())\n",
    "                obj_with_df_and_symbol.informative_dataframes[timeframe] = informative_df\n",
    "            else:\n",
    "                informative_df = obj_with_df_and_symbol.informative_dataframes[timeframe]\n",
    "\n",
    "            obj_with_df_and_symbol.df = merge_informative_data(\n",
    "                obj_with_df_and_symbol.df,\n",
    "                timeframe,\n",
    "                informative_df\n",
    "            )\n",
    "\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def merge_signals(signal_list):\n",
    "    if not signal_list:\n",
    "        return None\n",
    "    direction = signal_list[0][0]\n",
    "    reasons = sorted(set(sig[1] for sig in signal_list))\n",
    "    merged_reason = \"_\".join(reasons)\n",
    "    return (direction, merged_reason)\n",
    "\n",
    "def merge_levels(level_list, direction=\"long\", close_price=None):\n",
    "    if not level_list:\n",
    "        return None\n",
    "\n",
    "    min_distance_ratio = 0.0005  # 0.05%\n",
    "    max_sl_ratio = 0.003         # 0.3%\n",
    "    min_sl_ratio = 0.001         # 0.1%\n",
    "\n",
    "    # üîπ Zbierz unikalne tagi (dla informacji)\n",
    "    tags = [level.get(\"tag\", \"?\") for level in level_list]\n",
    "    combined_tag = \"_\".join(sorted(set(tags)))\n",
    "\n",
    "    sl_all, tp1_all, tp2_all = [], [], []\n",
    "\n",
    "    # üîπ Zbierz wszystkie poziomy SL/TP z level[\"extra\"]\n",
    "    for level in level_list:\n",
    "        extra = level.get(\"extra\", {}) or {}\n",
    "        sl_val = extra.get(\"sl\")\n",
    "        tp1_val = extra.get(\"tp1\")\n",
    "        tp2_val = extra.get(\"tp2\")\n",
    "\n",
    "        if sl_val is not None:\n",
    "            sl_all.append((level[\"source\"], sl_val))\n",
    "        if tp1_val is not None:\n",
    "            tp1_all.append((level[\"source\"], tp1_val))\n",
    "        if tp2_val is not None:\n",
    "            tp2_all.append((level[\"source\"], tp2_val))\n",
    "\n",
    "    # üîπ Uzupe≈Çnij brakujƒÖce poziomy (na podstawie ceny close)\n",
    "    if close_price is not None:\n",
    "        if not sl_all:\n",
    "            sl_value = close_price - (close_price * min_distance_ratio * 1.2) if direction == \"long\" else close_price + (close_price * min_distance_ratio * 1.2)\n",
    "            sl_all.append((\"auto\", sl_value))\n",
    "        if not tp1_all:\n",
    "            tp1_value = close_price + (close_price * min_distance_ratio * 2) if direction == \"long\" else close_price - (close_price * min_distance_ratio * 2)\n",
    "            tp1_all.append((\"auto\", tp1_value))\n",
    "        if not tp2_all:\n",
    "            tp2_value = close_price + (close_price * min_distance_ratio * 3) if direction == \"long\" else close_price - (close_price * min_distance_ratio * 3)\n",
    "            tp2_all.append((\"auto\", tp2_value))\n",
    "\n",
    "    # üîπ Wybierz finalne warto≈õci\n",
    "    if direction == \"long\":\n",
    "        sl_final = min(sl_all, key=lambda x: x[1])\n",
    "        tp1_final = max(tp1_all, key=lambda x: x[1])\n",
    "        tp2_final = max(tp2_all, key=lambda x: x[1])\n",
    "    else:\n",
    "        sl_final = max(sl_all, key=lambda x: x[1])\n",
    "        tp1_final = min(tp1_all, key=lambda x: x[1])\n",
    "        tp2_final = min(tp2_all, key=lambda x: x[1])\n",
    "\n",
    "    # üîπ Walidacja odleg≈Ço≈õci SL / TP wzglƒôdem ceny close\n",
    "    if close_price is not None:\n",
    "        risk = abs(close_price - sl_final[1])\n",
    "        max_allowed_risk = close_price * max_sl_ratio\n",
    "        min_sl = close_price * min_sl_ratio\n",
    "\n",
    "        # Zbyt ma≈Çy SL ‚Üí wymu≈õ minimalny dystans\n",
    "        if risk < min_sl:\n",
    "            new_sl_price = close_price - min_sl if direction == \"long\" else close_price + min_sl\n",
    "            sl_final = (\"min_0.1%\", new_sl_price)\n",
    "\n",
    "        # RR check i korekta TP\n",
    "        risk = abs(close_price - sl_final[1])\n",
    "        reward_tp1 = abs(tp1_final[1] - close_price)\n",
    "        reward_tp2 = abs(tp2_final[1] - close_price)\n",
    "\n",
    "        # Wyr√≥wnaj TP1/TP2 dla lepszego RR\n",
    "        if reward_tp1 / risk < 2:\n",
    "            new_tp1 = close_price + risk * 2 if direction == \"long\" else close_price - risk * 2\n",
    "            tp1_final = (\"RR_1:2\", new_tp1)\n",
    "\n",
    "        if reward_tp2 / risk < 4:\n",
    "            new_tp2 = close_price + risk * 4 if direction == \"long\" else close_price - risk * 4\n",
    "            tp2_final = (\"RR_1:4\", new_tp2)\n",
    "\n",
    "        if reward_tp1 / risk > 3:\n",
    "            new_tp1 = close_price + risk * 3 if direction == \"long\" else close_price - risk * 3\n",
    "            tp1_final = (\"RR_1:3\", new_tp1)\n",
    "\n",
    "        if reward_tp2 / risk > 6:\n",
    "            new_tp2 = close_price + risk * 6 if direction == \"long\" else close_price - risk * 6\n",
    "            tp2_final = (\"RR_1:6\", new_tp2)\n",
    "\n",
    "    return (\n",
    "        (\"SL\", sl_final[1], f\"SL_{sl_final[0]}_{combined_tag}\"),\n",
    "        (\"TP\", tp1_final[1], f\"TP1_{tp1_final[0]}_{combined_tag}\"),\n",
    "        (\"TP\", tp2_final[1], f\"TP2_{tp2_final[0]}_{combined_tag}\")\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Poi:\n",
    "    def __init__(self, df: pd.DataFrame, symbol, startup_candle_count: int = 600):\n",
    "        self.startup_candle_count = startup_candle_count\n",
    "        self.df = df.copy()\n",
    "        self.symbol = symbol\n",
    "        self.informative_dataframes = {}\n",
    "        # Inicjalizacja klasy SmartMoneyConcepts\n",
    "        \n",
    "        self.smc = SmartMoneyConcepts(self.df)\n",
    "        self.sessions = SessionsSMC(self.df)\n",
    "        self.sessions_h1 = None\n",
    "\n",
    "    @informative('H1')\n",
    "    def populate_indicators_H1(self, df: pd.DataFrame):\n",
    "\n",
    "        df['idx'] = df.index\n",
    "        df['atr'] = ta.ATR(df, 14)\n",
    "\n",
    "\n",
    "        # Aktualizujemy niezale≈ºne instancje\n",
    "        self.smc.df = df.copy()\n",
    "        self.smc.find_validate_zones(tf=\"H1\")\n",
    "\n",
    "        self.sessions_h1 = SessionsSMC(df.copy())\n",
    "        self.sessions_h1.df = self.sessions_h1.calculate_previous_ranges()\n",
    "\n",
    "        # Zwracamy co≈õ, by merge m√≥g≈Ç zadzia≈Çaƒá\n",
    "        return df\n",
    "\n",
    "    def populate_indicators(self):\n",
    "        self.df = self.df.rename(columns={'time_x': 'time'})\n",
    "        if 'time_y' in self.df.columns:\n",
    "            self.df = self.df.drop(columns=['time_y'])\n",
    "\n",
    "        self.df['idx'] = self.df.index\n",
    "        self.df['atr'] = ta.ATR(self.df, 14)\n",
    "        heikinashi = qtpylib.heikinashi(self.df)\n",
    "        self.df[['ha_open', 'ha_close', 'ha_high', 'ha_low']] = heikinashi[['open', 'close', 'high', 'low']]\n",
    "\n",
    "        self.df['candle_bullish'] = (\n",
    "            qtpylib.candlestick_confirmation(self.df, 'bullish')\n",
    "        )\n",
    "        self.df['candle_bearish'] = (\n",
    "            qtpylib.candlestick_confirmation(self.df, 'bearish')\n",
    "        )\n",
    "\n",
    "        first_high = self.df['high'].shift(2)\n",
    "        first_low = self.df['low'].shift(2)\n",
    "\n",
    "        self.df['min_5'] = self.df['low'].rolling(5).min()\n",
    "        self.df['max_5'] = self.df['high'].rolling(5).max()\n",
    "\n",
    "        cisd_bull_cond = ((self.df['high'] < first_low))\n",
    "        cisd_bear_cond = ((self.df['low'] > first_high))\n",
    "\n",
    "        self.df.loc[cisd_bull_cond, 'cisd_bull_line'] = first_low\n",
    "        self.df.loc[cisd_bear_cond, 'cisd_bear_line'] = first_high\n",
    "\n",
    "        self.df[f'cisd_bull_line'] = self.df[f'cisd_bull_line'].ffill()\n",
    "        self.df[f'cisd_bear_line'] = self.df[f'cisd_bear_line'].ffill()\n",
    "\n",
    "        # Aktualizujemy r√≥wnie≈º na M5\n",
    "        self.smc.df = self.df.copy()\n",
    "        self.smc.find_validate_zones(tf=\"M5\")\n",
    "        self.smc.detect_reaction()\n",
    "\n",
    "        self.sessions.df = self.df.copy()\n",
    "        self.sessions.calculate_sessions_ranges()\n",
    "\n",
    "        if self.sessions_h1 is not None:\n",
    "            self.sessions.df = pd.merge_asof(\n",
    "                self.sessions.df.sort_values('time'),\n",
    "                self.sessions_h1.df.sort_values('time'),\n",
    "                on='time',\n",
    "                direction='backward',\n",
    "                suffixes=('', '_H1')\n",
    "            )\n",
    "\n",
    "        self.sessions.detect_session_type()\n",
    "        self.sessions.detect_signals()\n",
    "\n",
    "    def merge_external_dfs(self):\n",
    "        \"\"\"\n",
    "        ≈ÅƒÖczy dane z:\n",
    "        - self.smc.df\n",
    "        - self.sessions.df\n",
    "        - sygna≈Çy z self.sessions.detect_signals()\n",
    "    \n",
    "        Pomija kolumny ju≈º obecne w self.df.\n",
    "        \"\"\"\n",
    "        base = self.df.copy()\n",
    "    \n",
    "        # --- ≈ÅƒÖczenie z self.smc.df ---\n",
    "        if hasattr(self, \"smc\") and hasattr(self.smc, \"df\"):\n",
    "            smc_df = self.smc.df.copy()\n",
    "            new_cols = [c for c in smc_df.columns if c not in base.columns]\n",
    "            if new_cols:\n",
    "                base = base.merge(smc_df[['time'] + new_cols], on='time', how='left', validate='1:1')\n",
    "    \n",
    "        # --- ≈ÅƒÖczenie z self.sessions.df ---\n",
    "        if hasattr(self, \"sessions\") and hasattr(self.sessions, \"df\"):\n",
    "            sessions_df = self.sessions.df.copy()\n",
    "            new_cols = [c for c in sessions_df.columns if c not in base.columns]\n",
    "            if new_cols:\n",
    "                base = base.merge(sessions_df[['time'] + new_cols], on='time', how='left', validate='1:1')\n",
    "\n",
    "        \n",
    "    \n",
    "        self.df = base\n",
    "\n",
    "        print(f\"Kolumny self.df: {list(self.df.columns)}\")\n",
    "\n",
    "    def calculate_levels(self, signals, close):\n",
    "\n",
    "        if not isinstance(signals, dict):\n",
    "            return None\n",
    "\n",
    "        direction = signals.get(\"direction\")\n",
    "        tag = signals.get(\"tag\")\n",
    "\n",
    "        risk = close * 0.001  # np. 0.1%\n",
    "        rr1 = 2\n",
    "        rr2 = 4\n",
    "\n",
    "        if direction == \"long\":\n",
    "            sl = close - risk\n",
    "            tp1 = close + risk * rr1\n",
    "            tp2 = close + risk * rr2\n",
    "        else:\n",
    "            sl = close + risk\n",
    "            tp1 = close - risk * rr1\n",
    "            tp2 = close - risk * rr2\n",
    "\n",
    "        return {\n",
    "            \"SL\": {\"level\": sl, \"tag\": \"auto\"},\n",
    "            \"TP1\": {\"level\": tp1, \"tag\": \"RR_1:2\"},\n",
    "            \"TP2\": {\"level\": tp2, \"tag\": \"RR_1:4\"},\n",
    "        }\n",
    "\n",
    "    def populate_entry_trend(self):\n",
    "        \"\"\"\n",
    "        Buduje sygna≈Çy wej≈õcia ≈ÇƒÖczƒÖce:\n",
    "        - kierunek sesyjny (sessions_signal)\n",
    "        - kierunek dnia (prev_day_direction)\n",
    "        - bias rynkowy (session_bias)\n",
    "        - strefy HTF/LTF (OB, FVG, Breaker)\n",
    "        \"\"\"\n",
    "\n",
    "        df = self.df.copy()\n",
    "\n",
    "        # --- üîπ 1. Agregacja stref ---\n",
    "        def merge_flags(prefix):\n",
    "            return df[f\"{prefix}_reaction_H1\"] | df[f\"{prefix}_in_zone_H1\"], \\\n",
    "                   df[f\"{prefix}_reaction\"] | df[f\"{prefix}_in_zone\"]\n",
    "\n",
    "        for side in [\"bullish\", \"bearish\"]:\n",
    "            for zone in [\"breaker\", \"fvg\", \"ob\"]:\n",
    "                df[f\"{side}_{zone}_H1\"], df[f\"{side}_{zone}\"] = merge_flags(f\"{side}_{zone}\")\n",
    "\n",
    "        # --- üîπ 2. Listy aktywnych stref ---\n",
    "        def active_cols(df, side, timeframe):\n",
    "            cols = [f\"{side}_breaker{timeframe}\", f\"{side}_ob{timeframe}\", f\"{side}_fvg{timeframe}\"]\n",
    "            return df[cols].apply(lambda x: [col.split(\"_\")[1].upper() for col in x.index if x[col]], axis=1)\n",
    "\n",
    "        df[\"htf_long_active\"] = active_cols(df, \"bullish\", \"_H1\")\n",
    "        df[\"ltf_long_active\"] = active_cols(df, \"bullish\", \"\")\n",
    "        df[\"htf_short_active\"] = active_cols(df, \"bearish\", \"_H1\")\n",
    "        df[\"ltf_short_active\"] = active_cols(df, \"bearish\", \"\")\n",
    "\n",
    "        # --- üîπ 3. Bias i kierunek dnia ---\n",
    "        df[\"prev_day_direction\"] = np.where(df[\"prev_close\"] > df[\"prev_open\"], \"bullish\",\n",
    "                                            np.where(df[\"prev_close\"] < df[\"prev_open\"], \"bearish\", None))\n",
    "        df[\"session_bias\"] = np.where(df[\"close\"] > df[\"PDH\"], \"bullish\",\n",
    "                                      np.where(df[\"close\"] < df[\"PDL\"], \"bearish\", \"neutral\"))\n",
    "\n",
    "        # --- üîπ 4. Inicjalizacja sygna≈Ç√≥w ---\n",
    "        df[\"signal_entry\"] = None\n",
    "        df[\"signal_strength\"] = 0.0\n",
    "\n",
    "        # --- üîπ 5. Maski logiczne ---\n",
    "        long_mask = (\n",
    "                (df[\"sessions_signal\"] == \"long\")\n",
    "                #(df[\"session_bias\"] == \"bullish\") &\n",
    "                #(df[\"prev_day_direction\"] == \"bullish\") &\n",
    "                #(df[\"htf_long_active\"].apply(len) > 0) &\n",
    "                #(df[\"ltf_long_active\"].apply(len) > 0)\n",
    "        )\n",
    "\n",
    "        short_mask = (\n",
    "                (df[\"sessions_signal\"] == \"short\")\n",
    "                #(df[\"session_bias\"] == \"bearish\") &\n",
    "                #(df[\"prev_day_direction\"] == \"bearish\") &\n",
    "                #(df[\"htf_short_active\"].apply(len) > 0) &\n",
    "                #(df[\"ltf_short_active\"].apply(len) > 0)\n",
    "        )\n",
    "\n",
    "        # --- üîπ 6. Generowanie sygna≈Ç√≥w + scoring ---\n",
    "        def build_entry(row, direction):\n",
    "            htf = row[f\"htf_{direction}_active\"]\n",
    "            ltf = row[f\"ltf_{direction}_active\"]\n",
    "            score = len(htf) + len(ltf)\n",
    "            tag = f\"{row['session_context']}__{row['session_bias']}__{direction.upper()}__HTF:{'-'.join(htf)}__LTF:{'-'.join(ltf)}\"\n",
    "            return {\"direction\": direction, \"tag\": tag}, score\n",
    "\n",
    "        df.loc[long_mask, [\"signal_entry\", \"signal_strength\"]] = df.loc[long_mask].apply(\n",
    "            lambda r: build_entry(r, \"long\"), axis=1, result_type=\"expand\"\n",
    "        )\n",
    "\n",
    "        df.loc[short_mask, [\"signal_entry\", \"signal_strength\"]] = df.loc[short_mask].apply(\n",
    "            lambda r: build_entry(r, \"short\"), axis=1, result_type=\"expand\"\n",
    "        )\n",
    "\n",
    "        # --- üîπ 7. Poziomy SL/TP ---\n",
    "        has_signals = df[\"signal_entry\"].apply(bool)\n",
    "        df.loc[has_signals, \"levels\"] = df.loc[has_signals].apply(\n",
    "            lambda row: self.calculate_levels(row[\"signal_entry\"], row[\"close\"]),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        print(\"here\")\n",
    "        print(df[df[\"signal_entry\"].notna()])\n",
    "\n",
    "        print(\"sessions_signal counts:\")\n",
    "        print(df[\"sessions_signal\"].value_counts(dropna=False))\n",
    "        \n",
    "        # 2. Ile wierszy spe≈Çnia podstawowe warunki (poszczeg√≥lne elementy maski)?\n",
    "        print(\"count sessions_signal == 'long':\", (df[\"sessions_signal\"] == \"long\").sum())\n",
    "        print(\"count sessions_signal == 'short':\", (df[\"sessions_signal\"] == \"short\").sum())\n",
    "        \n",
    "        # 3. Sprawd≈∫ htf/ltf ‚Äî czy rzeczywi≈õcie zwracajƒÖ listy i jakie sƒÖ ich d≈Çugo≈õci\n",
    "        print(\"htf_long_active non-empty:\", (df[\"htf_long_active\"].apply(lambda x: len(x) if isinstance(x, (list,tuple)) else 0) > 0).sum())\n",
    "        print(\"ltf_long_active non-empty:\", (df[\"ltf_long_active\"].apply(lambda x: len(x) if isinstance(x, (list,tuple)) else 0) > 0).sum())\n",
    "        print(\"htf_short_active non-empty:\", (df[\"htf_short_active\"].apply(lambda x: len(x) if isinstance(x, (list,tuple)) else 0) > 0).sum())\n",
    "        print(\"ltf_short_active non-empty:\", (df[\"ltf_short_active\"].apply(lambda x: len(x) if isinstance(x, (list,tuple)) else 0) > 0).sum())\n",
    "        \n",
    "        # 4. Sprawd≈∫ biasy i kierunek poprzedniego dnia\n",
    "        print(\"prev_day_direction unique:\", df[\"prev_day_direction\"].unique())\n",
    "        print(\"session_bias unique:\", df[\"session_bias\"].unique())\n",
    "        \n",
    "        # 5. Poka≈º pierwsze N wierszy gdzie sessions_signal nie jest NaN (je≈õli w og√≥le sƒÖ)\n",
    "        print(df[df[\"sessions_signal\"].notna()].head(10))\n",
    "\n",
    "        self.df = df\n",
    "        return df\n",
    "\n",
    "    def populate_exit_trend(self):\n",
    "\n",
    "        df = self.df\n",
    "\n",
    "        df['signal_exit'] = None\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def get_bullish_zones(self):\n",
    "        return []\n",
    "\n",
    "    def get_bearish_zones(self):\n",
    "        return []\n",
    "\n",
    "    def get_extra_values_to_plot(self):\n",
    "        return [\n",
    "            #(\"london_high\", self.sessions.df[\"london_main_high\"], \"blue\", \"dot\"),\n",
    "            #(\"london_low\", self.sessions.df[\"london_main_low\"], \"blue\", \"dot\"),\n",
    "            #(\"asia_high\", self.sessions.df[\"asia_main_high\"], \"purple\", \"dot\"),\n",
    "            #(\"asia_low\", self.sessions.df[\"asia_main_low\"], \"purple\", \"dot\"),\n",
    "            #(\"ny_high\", self.sessions.df[\"ny_main_high\"], \"orange\", \"dash\"),\n",
    "            #(\"ny_low\", self.sessions.df[\"ny_main_low\"], \"orange\", \"dash\"),\n",
    "\n",
    "            #(\"PDH\", self.sessions.df[\"PDH\"], \"blue\"),\n",
    "            #(\"PDL\", self.sessions.df[\"PDL\"], \"blue\"),\n",
    "\n",
    "            #(\"PWH\", self.sessions.df[\"PWH\"], \"yellow\"),\n",
    "            #(\"PWL\", self.sessions.df[\"PWL\"], \"yellow\"),\n",
    "        ]\n",
    "\n",
    "    def get_bullish_zones(self):\n",
    "        return [\n",
    "            #(\"Bullish IFVG H1\", self.smc.bullish_ifvg_validated_H1, \"rgba(255, 160, 122, 0.7)\"),\n",
    "            # Pomara≈Ñcz (pozostawiony bez zmian)\n",
    "            # (\"Bullish IFVG\", self.bullish_ifvg_validated, \"rgba(139, 0, 0, 1)\"),\n",
    "\n",
    "            #(\"Bullish FVG H1\", self.smc.bullish_fvg_validated_H1, \"rgba(255, 152, 0, 0.7)\"),  # Jasnoniebieski\n",
    "            # (\"Bullish FVG\", self.bullish_fvg_validated, \"rgba(255, 152, 0, 0.7)\"),             # Ciemnoniebieski\n",
    "\n",
    "            (\"Bullish OB H1\", self.smc.bullish_ob_validated_H1, \"rgba(144, 238, 144, 0.7)\"),  # Jasnozielony\n",
    "            # (\"Bullish OB\", self.bullish_ob_validated, \"rgba(0, 100, 0, 1)\"),           # Ciemnozielony\n",
    "\n",
    "            (\"Bullish Breaker H1\", self.smc.bullish_breaker_validated_H1, \"rgba(173, 216, 230, 0.7)\"),  # Jasnoniebieski\n",
    "            # (\"Bullish Breaker\", self.bullish_breaker_validated, \"rgba(0, 0, 139, 1)\"),             # Ciemnoniebieski\n",
    "\n",
    "            # (\"Bullish GAP \", self.bullish_gap_validated, \"rgba(56, 142, 60, 1)\"),\n",
    "        ]\n",
    "\n",
    "    def get_bearish_zones(self):\n",
    "        return [\n",
    "            # (\"Bearish Breaker\", self.smc.bearish_breaker_validated, \"rgba(64, 64, 64, 1)\"),      # Ciemnoszary\n",
    "             (\"Bearish Breaker H1\", self.smc.bearish_breaker_validated_H1, \"rgba(169, 169, 169, 0.7)\"),  # Jasnoszary\n",
    "\n",
    "            # (\"Bearish OB\", self.smc.bearish_ob_validated, \"rgba(139, 0, 0, 1)\"),                # Ciemnoczerwony\n",
    "             (\"Bearish OB H1\", self.smc.bearish_ob_validated_H1, \"rgba(255, 160, 122, 0.7)\"),       # Jasnoczerwony\n",
    "\n",
    "            # (\"Bearish IFVG H1\", self.smc.bearish_ifvg_validated_H1, \"rgba(139, 0, 0, 1)\"),  # Pomara≈Ñcz (pozostawiony bez zmian)\n",
    "            # (\"Bearish IFVG\", self.smc.bearish_ifvg_validated, \"rgba(255, 160, 122, 0.7)\"),\n",
    "\n",
    "            # (\"Bearish FVG\", self.smc.bearish_fvg_validated, \"rgba(0, 0, 139, 1)\"),      # Ciemnoszary\n",
    "            # (\"Bearish FVG H1\", self.smc.bearish_fvg_validated_H1, \"rgba(173, 216, 230, 0.7)\"),  # Jasnoszary\n",
    "        ]\n",
    "    \n",
    "    def bool_series(self):\n",
    "        return []\n",
    "\n",
    "\n",
    "    def run(self) -> pd.DataFrame:\n",
    "\n",
    "\n",
    "        timings = []  # Lista do przechowywania czas√≥w\n",
    "\n",
    "        def timeit(label, func):\n",
    "            start = time.time()\n",
    "            func()\n",
    "            end = time.time()\n",
    "            duration = end - start\n",
    "            timings.append((label, duration))\n",
    "            #print(f\"{label} finished in {duration:.4f} seconds\")\n",
    "\n",
    "        timeit(\"_populate_informative_indicators\", lambda: populate_informative_indicators(self))\n",
    "        timeit(\"self.populate_indicators()\", lambda: self.populate_indicators())\n",
    "        timeit(\"self.merge_external_dfs()\", lambda: self.merge_external_dfs())\n",
    "        timeit(\"self.populate_entry_trend()\", lambda: self.populate_entry_trend())\n",
    "\n",
    "        # 3Ô∏è‚É£ Zwr√≥ƒá ko≈Ñcowy DataFrame z M5 + H1 scalonymi danymi\n",
    "        print(\"\\n‚è±Ô∏è Profil czasu wykonania:\")\n",
    "        for label, duration in timings:\n",
    "            print(f\"   {label:<40} {duration:.3f}s\")\n",
    "\n",
    "\n",
    "\n",
    "        return self.sessions.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "073356c1-4d66-461d-95e6-719fc247a905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolumny self.df: ['time', 'open', 'high', 'low', 'close', 'tick_volume', 'time_H1', 'open_H1', 'high_H1', 'low_H1', 'close_H1', 'tick_volume_H1', 'spread_H1', 'real_volume_H1', 'idx_H1', 'atr_H1', 'idx', 'atr', 'ha_open', 'ha_close', 'ha_high', 'ha_low', 'min_5', 'max_5', 'cisd_bull_line', 'cisd_bear_line', 'candle_form', 'candle_bullish', 'candle_bearish', 'bullish_fvg_in_zone', 'bullish_fvg_reaction', 'bullish_fvg_in_zone_H1', 'bullish_fvg_reaction_H1', 'bullish_ob_in_zone', 'bullish_ob_reaction', 'bullish_ob_in_zone_H1', 'bullish_ob_reaction_H1', 'bullish_breaker_in_zone', 'bullish_breaker_reaction', 'bullish_breaker_in_zone_H1', 'bullish_breaker_reaction_H1', 'bullish_ifvg_in_zone', 'bullish_ifvg_reaction', 'bullish_ifvg_in_zone_H1', 'bullish_ifvg_reaction_H1', 'bearish_fvg_in_zone', 'bearish_fvg_reaction', 'bearish_fvg_in_zone_H1', 'bearish_fvg_reaction_H1', 'bearish_ob_in_zone', 'bearish_ob_reaction', 'bearish_ob_in_zone_H1', 'bearish_ob_reaction_H1', 'bearish_breaker_in_zone', 'bearish_breaker_reaction', 'bearish_breaker_in_zone_H1', 'bearish_breaker_reaction_H1', 'bearish_ifvg_in_zone', 'bearish_ifvg_reaction', 'bearish_ifvg_in_zone_H1', 'bearish_ifvg_reaction_H1', 'asian_high', 'asian_low', 'london_high', 'london_low', 'ny_high', 'ny_low', 'asia_high', 'asia_low', 'spread', 'real_volume', 'date', 'weekday', 'week', 'year', 'hour', 'monday_high', 'monday_low', 'monday', 'PDH', 'PDL', 'weekly_high', 'weekly_low', 'PWH', 'PWL', 'prev_open', 'prev_close', 'session', 'sessions_signal', 'session_context', 'signal_strength']\n",
      "here\n",
      "Empty DataFrame\n",
      "Columns: [time, open, high, low, close, tick_volume, time_H1, open_H1, high_H1, low_H1, close_H1, tick_volume_H1, spread_H1, real_volume_H1, idx_H1, atr_H1, idx, atr, ha_open, ha_close, ha_high, ha_low, min_5, max_5, cisd_bull_line, cisd_bear_line, candle_form, candle_bullish, candle_bearish, bullish_fvg_in_zone, bullish_fvg_reaction, bullish_fvg_in_zone_H1, bullish_fvg_reaction_H1, bullish_ob_in_zone, bullish_ob_reaction, bullish_ob_in_zone_H1, bullish_ob_reaction_H1, bullish_breaker_in_zone, bullish_breaker_reaction, bullish_breaker_in_zone_H1, bullish_breaker_reaction_H1, bullish_ifvg_in_zone, bullish_ifvg_reaction, bullish_ifvg_in_zone_H1, bullish_ifvg_reaction_H1, bearish_fvg_in_zone, bearish_fvg_reaction, bearish_fvg_in_zone_H1, bearish_fvg_reaction_H1, bearish_ob_in_zone, bearish_ob_reaction, bearish_ob_in_zone_H1, bearish_ob_reaction_H1, bearish_breaker_in_zone, bearish_breaker_reaction, bearish_breaker_in_zone_H1, bearish_breaker_reaction_H1, bearish_ifvg_in_zone, bearish_ifvg_reaction, bearish_ifvg_in_zone_H1, bearish_ifvg_reaction_H1, asian_high, asian_low, london_high, london_low, ny_high, ny_low, asia_high, asia_low, spread, real_volume, date, weekday, week, year, hour, monday_high, monday_low, monday, PDH, PDL, weekly_high, weekly_low, PWH, PWL, prev_open, prev_close, session, sessions_signal, session_context, signal_strength, bullish_breaker_H1, bullish_breaker, bullish_fvg_H1, bullish_fvg, bullish_ob_H1, bullish_ob, bearish_breaker_H1, bearish_breaker, bearish_fvg_H1, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 111 columns]\n",
      "sessions_signal counts:\n",
      "sessions_signal\n",
      "None     52639\n",
      "long      3349\n",
      "short     2721\n",
      "Name: count, dtype: int64\n",
      "count sessions_signal == 'long': 3349\n",
      "count sessions_signal == 'short': 2721\n",
      "htf_long_active non-empty: 10204\n",
      "ltf_long_active non-empty: 13992\n",
      "htf_short_active non-empty: 11899\n",
      "ltf_short_active non-empty: 16241\n",
      "prev_day_direction unique: [None 'bearish' 'bullish']\n",
      "session_bias unique: ['neutral' 'bearish' 'bullish']\n",
      "                         time     open     high      low    close  \\\n",
      "853 2025-01-07 09:05:00+00:00  1.03999  1.04053  1.03998  1.04052   \n",
      "854 2025-01-07 09:10:00+00:00  1.04052  1.04096  1.04052  1.04086   \n",
      "855 2025-01-07 09:15:00+00:00  1.04087  1.04126  1.04064  1.04126   \n",
      "856 2025-01-07 09:20:00+00:00  1.04127  1.04147  1.04108  1.04129   \n",
      "857 2025-01-07 09:25:00+00:00  1.04129  1.04154  1.04123  1.04124   \n",
      "858 2025-01-07 09:30:00+00:00  1.04125  1.04134  1.04099  1.04120   \n",
      "859 2025-01-07 09:35:00+00:00  1.04120  1.04182  1.04110  1.04179   \n",
      "860 2025-01-07 09:40:00+00:00  1.04181  1.04240  1.04171  1.04224   \n",
      "861 2025-01-07 09:45:00+00:00  1.04224  1.04228  1.04106  1.04118   \n",
      "862 2025-01-07 09:50:00+00:00  1.04118  1.04165  1.04103  1.04104   \n",
      "\n",
      "     tick_volume                   time_H1  open_H1  high_H1  low_H1  ...  \\\n",
      "853          308 2025-01-07 09:00:00+00:00   1.0397   1.0424  1.0397  ...   \n",
      "854          378 2025-01-07 09:00:00+00:00   1.0397   1.0424  1.0397  ...   \n",
      "855          312 2025-01-07 09:00:00+00:00   1.0397   1.0424  1.0397  ...   \n",
      "856          405 2025-01-07 09:00:00+00:00   1.0397   1.0424  1.0397  ...   \n",
      "857          315 2025-01-07 09:00:00+00:00   1.0397   1.0424  1.0397  ...   \n",
      "858          478 2025-01-07 09:00:00+00:00   1.0397   1.0424  1.0397  ...   \n",
      "859          421 2025-01-07 09:00:00+00:00   1.0397   1.0424  1.0397  ...   \n",
      "860          508 2025-01-07 09:00:00+00:00   1.0397   1.0424  1.0397  ...   \n",
      "861          837 2025-01-07 09:00:00+00:00   1.0397   1.0424  1.0397  ...   \n",
      "862          612 2025-01-07 09:00:00+00:00   1.0397   1.0424  1.0397  ...   \n",
      "\n",
      "     bearish_ob_H1  bearish_ob  htf_long_active  ltf_long_active  \\\n",
      "853          False       False               []               []   \n",
      "854          False       False               []            [FVG]   \n",
      "855          False       False               []               []   \n",
      "856          False       False               []               []   \n",
      "857          False       False               []               []   \n",
      "858          False       False               []               []   \n",
      "859          False       False               []               []   \n",
      "860          False       False               []               []   \n",
      "861          False       False               []               []   \n",
      "862          False       False               []               []   \n",
      "\n",
      "     htf_short_active  ltf_short_active  prev_day_direction  session_bias  \\\n",
      "853    [BREAKER, FVG]             [FVG]             bullish       neutral   \n",
      "854    [BREAKER, FVG]             [FVG]             bullish       neutral   \n",
      "855             [FVG]                []             bullish       neutral   \n",
      "856             [FVG]                []             bullish       neutral   \n",
      "857             [FVG]                []             bullish       neutral   \n",
      "858             [FVG]                []             bullish       neutral   \n",
      "859             [FVG]                []             bullish       neutral   \n",
      "860    [BREAKER, FVG]                []             bullish       neutral   \n",
      "861    [BREAKER, FVG]                []             bullish       neutral   \n",
      "862    [BREAKER, FVG]                []             bullish       neutral   \n",
      "\n",
      "     signal_entry  levels  \n",
      "853           NaN    None  \n",
      "854           NaN    None  \n",
      "855           NaN    None  \n",
      "856           NaN    None  \n",
      "857           NaN    None  \n",
      "858           NaN    None  \n",
      "859           NaN    None  \n",
      "860           NaN    None  \n",
      "861           NaN    None  \n",
      "862           NaN    None  \n",
      "\n",
      "[10 rows x 111 columns]\n",
      "\n",
      "‚è±Ô∏è Profil czasu wykonania:\n",
      "   _populate_informative_indicators         0.080s\n",
      "   self.populate_indicators()               6.081s\n",
      "   self.merge_external_dfs()                0.066s\n",
      "   self.populate_entry_trend()              1.820s\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'iterrows'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      6\u001b[39m df_bt = poi.run()\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m#print(\"\\nüìä === INFORMACJE O self.smc.df ===\")\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m#print(f\"Kszta≈Çt: {df_bt.shape}\")\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m#print(f\"Kolumny: {list(df_bt.columns)}\")\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m#print(\"\\nPrzyk≈Çadowe dane:\")\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m#print(df_bt.head(5))\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43mplot_trades_with_indicators\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf_bt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEURUSD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbullish_zones\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpoi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_bullish_zones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbearish_zones\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpoi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_bearish_zones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextra_series\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpoi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_extra_values_to_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbool_series\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpoi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbool_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\PandasAlgoTrader\\backtesting\\plot.py:95\u001b[39m, in \u001b[36mplot_trades_with_indicators\u001b[39m\u001b[34m(df, trades, bullish_zones, bearish_zones, extra_series, bool_series, save_path)\u001b[39m\n\u001b[32m     85\u001b[39m fig.add_trace(go.Candlestick(x=df[\u001b[33m'\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     86\u001b[39m                             \u001b[38;5;28mopen\u001b[39m=df[\u001b[33m'\u001b[39m\u001b[33mopen\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     87\u001b[39m                             high=df[\u001b[33m'\u001b[39m\u001b[33mhigh\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     88\u001b[39m                             low=df[\u001b[33m'\u001b[39m\u001b[33mlow\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     89\u001b[39m                             close=df[\u001b[33m'\u001b[39m\u001b[33mclose\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     90\u001b[39m                             name=\u001b[33m'\u001b[39m\u001b[33mcandlestick\u001b[39m\u001b[33m'\u001b[39m), row=\u001b[32m1\u001b[39m, col=\u001b[32m1\u001b[39m)\n\u001b[32m     92\u001b[39m shown_legend = {\u001b[33m\"\u001b[39m\u001b[33mEntry\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcustom_SL\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcustom_TP\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mmanual_exit\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mTP1\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, trade \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrades\u001b[49m\u001b[43m.\u001b[49m\u001b[43miterrows\u001b[49m():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28mprint\u001b[39m()\n\u001b[32m     97\u001b[39m     add_trade_marker(\n\u001b[32m     98\u001b[39m         fig=fig,\n\u001b[32m     99\u001b[39m         x=trade[\u001b[33m'\u001b[39m\u001b[33mentry_time\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    108\u001b[39m         showlegend=\u001b[38;5;129;01mnot\u001b[39;00m shown_legend[\u001b[33m\"\u001b[39m\u001b[33mEntry\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    109\u001b[39m     )\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'iterrows'"
     ]
    }
   ],
   "source": [
    "from backtesting.plot import plot_trades_with_indicators\n",
    "\n",
    "poi = Poi(df=data, symbol=\"EURUSD\")\n",
    "\n",
    "\n",
    "df_bt = poi.run()\n",
    "\n",
    "\n",
    "\n",
    "#print(\"\\nüìä === INFORMACJE O self.smc.df ===\")\n",
    "#print(f\"Kszta≈Çt: {df_bt.shape}\")\n",
    "#print(f\"Kolumny: {list(df_bt.columns)}\")\n",
    "#print(\"\\nPrzyk≈Çadowe dane:\")\n",
    "#print(df_bt.head(5))\n",
    "\n",
    "         \n",
    "plot_trades_with_indicators(\n",
    "    df_bt,\n",
    "    \"EURUSD\",\n",
    "    bullish_zones=poi.get_bullish_zones(),\n",
    "    bearish_zones=poi.get_bearish_zones(),\n",
    "    extra_series=poi.get_extra_values_to_plot(),\n",
    "    bool_series=poi.bool_series(),\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e65a6e0-fd66-4156-b94c-c87703fbaedf",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a9365c-6f35-4396-bc53-cee2fe9b7c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4ef071-3988-4b8f-8a8e-b687330a2adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a04224-565e-4d13-ba59-767477eb4817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dc5ef8-3e9d-42c2-8bee-638d4bc2665b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
