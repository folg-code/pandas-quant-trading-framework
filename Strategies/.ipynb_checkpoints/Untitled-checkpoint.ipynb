{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2770b30b-b382-4821-b216-71434c8fb873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "BASE_DIR = os.path.abspath(os.path.join('..'))  # je≈õli notebook w Strategies/notebook\n",
    "sys.path.append(BASE_DIR)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import MetaTrader5 as mt5\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import config\n",
    "\n",
    "def get_live_data(symbol, timeframe, candle_lookback):\n",
    "\n",
    "    if not mt5.initialize():\n",
    "        raise RuntimeError(f\"MT5 initialize failed: {mt5.last_error()}\")\n",
    "\n",
    "    if not mt5.symbol_select(symbol, True):\n",
    "        mt5.symbol_select(symbol, False)  # Deselect\n",
    "        time.sleep(0.5)\n",
    "        if not mt5.symbol_select(symbol, True):\n",
    "            raise RuntimeError(f\"Still can't select symbol: {symbol}\")\n",
    "\n",
    "    rates = mt5.copy_rates_from_pos(symbol, timeframe, 0, candle_lookback)\n",
    "\n",
    "    if rates is None or len(rates) == 0:\n",
    "        raise ValueError(\"Brak danych dla podanego zakresu dat.\")\n",
    "\n",
    "    df = pd.DataFrame(rates)\n",
    "\n",
    "    df['time'] = pd.to_datetime(df['time'], unit='s', utc=True)\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "def pandas_freq_from_timeframe(tf: str) -> str:\n",
    "    mapping = {\n",
    "        'H1': '1h',\n",
    "        'H4': '4h',\n",
    "        'D1': '1d',\n",
    "        'M1': '1min',\n",
    "        'M5': '5min',\n",
    "        'M15': '15min',\n",
    "    }\n",
    "    return mapping.get(tf.upper(), tf)\n",
    "\n",
    "def get_data(symbol, timeframe, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Pobiera dane z MetaTrader 5 dla wybranego symbolu i przedzia≈Çu czasowego.\n",
    "\n",
    "    Args:\n",
    "        symbol (str): np. 'EURUSD'\n",
    "        timeframe (mt5.TIMEFRAME_*): np. mt5.TIMEFRAME_H1\n",
    "        start_date (datetime): data poczƒÖtkowa\n",
    "        end_date (datetime): data ko≈Ñcowa\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: dane OHLC + wolumen z datami\n",
    "    \"\"\"\n",
    "    # Inicjalizacja\n",
    "    if not mt5.initialize():\n",
    "        raise RuntimeError(f\"MT5 initialize failed: {mt5.last_error()}\")\n",
    "\n",
    "    # Pr√≥ba w≈ÇƒÖczenia symbolu\n",
    "    if not mt5.symbol_select(symbol, True):\n",
    "        time.sleep(0.5)\n",
    "        if not mt5.symbol_select(symbol, True):\n",
    "            mt5.shutdown()\n",
    "            raise RuntimeError(f\"Nie mo≈ºna wybraƒá symbolu: {symbol}\")\n",
    "\n",
    "    # Pobranie danych\n",
    "    rates = mt5.copy_rates_range(symbol, timeframe, start_date, end_date)\n",
    "    if rates is None or len(rates) == 0:\n",
    "        mt5.shutdown()\n",
    "        raise ValueError(f\"Brak danych dla {symbol} w podanym zakresie dat.\")\n",
    "\n",
    "    # Konwersja do DataFrame\n",
    "    df = pd.DataFrame(rates)\n",
    "    df['time'] = pd.to_datetime(df['time'], unit='s')\n",
    "    df = df[['time', 'open', 'high', 'low', 'close', 'tick_volume']]\n",
    "\n",
    "    # Zako≈Ñczenie po≈ÇƒÖczenia\n",
    "    mt5.shutdown()\n",
    "\n",
    "    return df\n",
    "\n",
    "def merge_informative_data(df: pd.DataFrame, timeframe: str, informative_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    freq = pandas_freq_from_timeframe(timeframe)\n",
    "    time_col = f'time_{timeframe}'\n",
    "\n",
    "    #print(f\"[merge_informative_data] Before timezone fix, df['time'] sample: {df['time'].head(3).tolist()}\")\n",
    "    if df['time'].dt.tz is None:\n",
    "        #print(\"[merge_informative_data] df['time'] is tz-naive, localizing...\")\n",
    "        df['time'] = df['time'].dt.tz_localize(config.SERVER_TIMEZONE)\n",
    "    else:\n",
    "        #print(f\"[merge_informative_data] df['time'] is tz-aware with tz: {df['time'].dt.tz}, converting...\")\n",
    "        df['time'] = df['time'].dt.tz_convert(config.SERVER_TIMEZONE)\n",
    "    #print(f\"[merge_informative_data] After fix, df['time'] sample: {df['time'].head(3).tolist()}\")\n",
    "\n",
    "    df[time_col] = df['time'].dt.tz_convert(config.SERVER_TIMEZONE).dt.floor(freq)\n",
    "    #print(f\"[merge_informative_data] Created column '{time_col}' sample: {df[time_col].head(3).tolist()}\")\n",
    "\n",
    "\n",
    "    informative_df = informative_df.rename(columns={\n",
    "        col: f\"{col}_{timeframe}\" for col in informative_df.columns if col != 'time'\n",
    "    })\n",
    "\n",
    "    merged = df.merge(\n",
    "        informative_df,\n",
    "        left_on=time_col,\n",
    "        right_on='time',\n",
    "        how='left'\n",
    "    )\n",
    "    #print(f\"[merge_informative_data] Merged dataframe length: {len(merged)}\")\n",
    "\n",
    "    return merged.drop(columns=['time'], errors='ignore')\n",
    "\n",
    "\n",
    "\n",
    "data = get_data(\"EURUSD\", mt5.TIMEFRAME_M5, datetime(2025,1,1), datetime(2025,10,20))\n",
    "data_H1 = get_data(\"EURUSD\", mt5.TIMEFRAME_H1, datetime(2025,1,1), datetime(2025,10,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6077d62b-63f8-4e11-9d85-192c5f6b025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.decorators import informative\n",
    "from TechnicalAnalysis.Indicators import indicators as qtpylib\n",
    "from TechnicalAnalysis.PointOfInterestSMC.core import SmartMoneyConcepts\n",
    "from TechnicalAnalysis.SessionsSMC.core import SessionsSMC\n",
    "\n",
    "import talib.abstract as ta\n",
    "\n",
    "def get_informative_dataframe(symbol, timeframe: str, startup_candle_count: int) -> pd.DataFrame:\n",
    "    freq = pandas_freq_from_timeframe(timeframe)\n",
    "    tf_minutes = pd.to_timedelta(freq).total_seconds() / 60\n",
    "    extra_minutes = tf_minutes * startup_candle_count\n",
    "\n",
    "    start_time = pd.to_datetime(config.TIMERANGE['start']).tz_localize(config.SERVER_TIMEZONE) - pd.to_timedelta(extra_minutes, unit='m')\n",
    "    end_time = pd.to_datetime(config.TIMERANGE['end']).tz_localize(config.SERVER_TIMEZONE)\n",
    "\n",
    "\n",
    "\n",
    "    df = get_live_data(\n",
    "        symbol,\n",
    "        getattr(mt5, f\"TIMEFRAME_{timeframe}\"),\n",
    "        6000\n",
    "    )\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "def populate_informative_indicators(obj_with_df_and_symbol):\n",
    "    for attr_name in dir(obj_with_df_and_symbol):\n",
    "        attr = getattr(obj_with_df_and_symbol, attr_name)\n",
    "        if callable(attr) and getattr(attr, '_informative', False):\n",
    "            timeframe = attr._informative_timeframe\n",
    "            if timeframe not in obj_with_df_and_symbol.informative_dataframes:\n",
    "                informative_df = get_informative_dataframe(\n",
    "                    symbol=obj_with_df_and_symbol.symbol,\n",
    "                    timeframe=timeframe,\n",
    "                    startup_candle_count=obj_with_df_and_symbol.startup_candle_count\n",
    "                )\n",
    "                informative_df = attr(df=informative_df.copy())\n",
    "                obj_with_df_and_symbol.informative_dataframes[timeframe] = informative_df\n",
    "            else:\n",
    "                informative_df = obj_with_df_and_symbol.informative_dataframes[timeframe]\n",
    "\n",
    "            obj_with_df_and_symbol.df = merge_informative_data(\n",
    "                obj_with_df_and_symbol.df,\n",
    "                timeframe,\n",
    "                informative_df\n",
    "            )\n",
    "\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def merge_signals(signal_list):\n",
    "    if not signal_list:\n",
    "        return None\n",
    "    direction = signal_list[0][0]\n",
    "    reasons = sorted(set(sig[1] for sig in signal_list))\n",
    "    merged_reason = \"_\".join(reasons)\n",
    "    return (direction, merged_reason)\n",
    "\n",
    "def merge_levels(level_list, direction=\"long\", close_price=None):\n",
    "    if not level_list:\n",
    "        return None\n",
    "\n",
    "    min_distance_ratio = 0.0005  # 0.05%\n",
    "    max_sl_ratio = 0.003         # 0.3%\n",
    "    min_sl_ratio = 0.001         # 0.1%\n",
    "\n",
    "    # üîπ Zbierz unikalne tagi (dla informacji)\n",
    "    tags = [level.get(\"tag\", \"?\") for level in level_list]\n",
    "    combined_tag = \"_\".join(sorted(set(tags)))\n",
    "\n",
    "    sl_all, tp1_all, tp2_all = [], [], []\n",
    "\n",
    "    # üîπ Zbierz wszystkie poziomy SL/TP z level[\"extra\"]\n",
    "    for level in level_list:\n",
    "        extra = level.get(\"extra\", {}) or {}\n",
    "        sl_val = extra.get(\"sl\")\n",
    "        tp1_val = extra.get(\"tp1\")\n",
    "        tp2_val = extra.get(\"tp2\")\n",
    "\n",
    "        if sl_val is not None:\n",
    "            sl_all.append((level[\"source\"], sl_val))\n",
    "        if tp1_val is not None:\n",
    "            tp1_all.append((level[\"source\"], tp1_val))\n",
    "        if tp2_val is not None:\n",
    "            tp2_all.append((level[\"source\"], tp2_val))\n",
    "\n",
    "    # üîπ Uzupe≈Çnij brakujƒÖce poziomy (na podstawie ceny close)\n",
    "    if close_price is not None:\n",
    "        if not sl_all:\n",
    "            sl_value = close_price - (close_price * min_distance_ratio * 1.2) if direction == \"long\" else close_price + (close_price * min_distance_ratio * 1.2)\n",
    "            sl_all.append((\"auto\", sl_value))\n",
    "        if not tp1_all:\n",
    "            tp1_value = close_price + (close_price * min_distance_ratio * 2) if direction == \"long\" else close_price - (close_price * min_distance_ratio * 2)\n",
    "            tp1_all.append((\"auto\", tp1_value))\n",
    "        if not tp2_all:\n",
    "            tp2_value = close_price + (close_price * min_distance_ratio * 3) if direction == \"long\" else close_price - (close_price * min_distance_ratio * 3)\n",
    "            tp2_all.append((\"auto\", tp2_value))\n",
    "\n",
    "    # üîπ Wybierz finalne warto≈õci\n",
    "    if direction == \"long\":\n",
    "        sl_final = min(sl_all, key=lambda x: x[1])\n",
    "        tp1_final = max(tp1_all, key=lambda x: x[1])\n",
    "        tp2_final = max(tp2_all, key=lambda x: x[1])\n",
    "    else:\n",
    "        sl_final = max(sl_all, key=lambda x: x[1])\n",
    "        tp1_final = min(tp1_all, key=lambda x: x[1])\n",
    "        tp2_final = min(tp2_all, key=lambda x: x[1])\n",
    "\n",
    "    # üîπ Walidacja odleg≈Ço≈õci SL / TP wzglƒôdem ceny close\n",
    "    if close_price is not None:\n",
    "        risk = abs(close_price - sl_final[1])\n",
    "        max_allowed_risk = close_price * max_sl_ratio\n",
    "        min_sl = close_price * min_sl_ratio\n",
    "\n",
    "        # Zbyt ma≈Çy SL ‚Üí wymu≈õ minimalny dystans\n",
    "        if risk < min_sl:\n",
    "            new_sl_price = close_price - min_sl if direction == \"long\" else close_price + min_sl\n",
    "            sl_final = (\"min_0.1%\", new_sl_price)\n",
    "\n",
    "        # RR check i korekta TP\n",
    "        risk = abs(close_price - sl_final[1])\n",
    "        reward_tp1 = abs(tp1_final[1] - close_price)\n",
    "        reward_tp2 = abs(tp2_final[1] - close_price)\n",
    "\n",
    "        # Wyr√≥wnaj TP1/TP2 dla lepszego RR\n",
    "        if reward_tp1 / risk < 2:\n",
    "            new_tp1 = close_price + risk * 2 if direction == \"long\" else close_price - risk * 2\n",
    "            tp1_final = (\"RR_1:2\", new_tp1)\n",
    "\n",
    "        if reward_tp2 / risk < 4:\n",
    "            new_tp2 = close_price + risk * 4 if direction == \"long\" else close_price - risk * 4\n",
    "            tp2_final = (\"RR_1:4\", new_tp2)\n",
    "\n",
    "        if reward_tp1 / risk > 3:\n",
    "            new_tp1 = close_price + risk * 3 if direction == \"long\" else close_price - risk * 3\n",
    "            tp1_final = (\"RR_1:3\", new_tp1)\n",
    "\n",
    "        if reward_tp2 / risk > 6:\n",
    "            new_tp2 = close_price + risk * 6 if direction == \"long\" else close_price - risk * 6\n",
    "            tp2_final = (\"RR_1:6\", new_tp2)\n",
    "\n",
    "    return (\n",
    "        (\"SL\", sl_final[1], f\"SL_{sl_final[0]}_{combined_tag}\"),\n",
    "        (\"TP\", tp1_final[1], f\"TP1_{tp1_final[0]}_{combined_tag}\"),\n",
    "        (\"TP\", tp2_final[1], f\"TP2_{tp2_final[0]}_{combined_tag}\")\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Poi:\n",
    "    def __init__(self, df: pd.DataFrame, symbol, startup_candle_count: int = 600):\n",
    "        self.startup_candle_count = startup_candle_count\n",
    "        self.df = df.copy()\n",
    "        self.symbol = symbol\n",
    "        self.informative_dataframes = {}\n",
    "        # Inicjalizacja klasy SmartMoneyConcepts\n",
    "        \n",
    "        self.smc = SmartMoneyConcepts(self.df)\n",
    "        self.sessions = SessionsSMC(self.df)\n",
    "        self.sessions_h1 = None\n",
    "\n",
    "    @informative('H1')\n",
    "    def populate_indicators_H1(self, df: pd.DataFrame):\n",
    "\n",
    "        df['idx'] = df.index\n",
    "        df['atr'] = ta.ATR(df, 14)\n",
    "\n",
    "\n",
    "        # Aktualizujemy niezale≈ºne instancje\n",
    "        self.smc.df = df.copy()\n",
    "        self.smc.find_validate_zones(tf=\"H1\")\n",
    "\n",
    "        self.sessions_h1 = SessionsSMC(df.copy())\n",
    "        self.sessions_h1.df = self.sessions_h1.calculate_previous_ranges()\n",
    "\n",
    "        # Zwracamy co≈õ, by merge m√≥g≈Ç zadzia≈Çaƒá\n",
    "        return df\n",
    "\n",
    "    def populate_indicators(self):\n",
    "        self.df = self.df.rename(columns={'time_x': 'time'})\n",
    "        if 'time_y' in self.df.columns:\n",
    "            self.df = self.df.drop(columns=['time_y'])\n",
    "\n",
    "        self.df['idx'] = self.df.index\n",
    "        self.df['atr'] = ta.ATR(self.df, 14)\n",
    "        heikinashi = qtpylib.heikinashi(self.df)\n",
    "        self.df[['ha_open', 'ha_close', 'ha_high', 'ha_low']] = heikinashi[['open', 'close', 'high', 'low']]\n",
    "\n",
    "        self.df['candle_bullish'] = (\n",
    "            qtpylib.candlestick_confirmation(self.df, 'bullish')\n",
    "        )\n",
    "        self.df['candle_bearish'] = (\n",
    "            qtpylib.candlestick_confirmation(self.df, 'bearish')\n",
    "        )\n",
    "\n",
    "        first_high = self.df['high'].shift(2)\n",
    "        first_low = self.df['low'].shift(2)\n",
    "\n",
    "        self.df['min_5'] = self.df['low'].rolling(5).min()\n",
    "        self.df['max_5'] = self.df['high'].rolling(5).max()\n",
    "\n",
    "        cisd_bull_cond = ((self.df['high'] < first_low))\n",
    "        cisd_bear_cond = ((self.df['low'] > first_high))\n",
    "\n",
    "        self.df.loc[cisd_bull_cond, 'cisd_bull_line'] = first_low\n",
    "        self.df.loc[cisd_bear_cond, 'cisd_bear_line'] = first_high\n",
    "\n",
    "        self.df[f'cisd_bull_line'] = self.df[f'cisd_bull_line'].ffill()\n",
    "        self.df[f'cisd_bear_line'] = self.df[f'cisd_bear_line'].ffill()\n",
    "\n",
    "        # Aktualizujemy r√≥wnie≈º na M5\n",
    "        self.smc.df = self.df.copy()\n",
    "        self.smc.find_validate_zones(tf=\"M5\")\n",
    "        self.smc.detect_reaction()\n",
    "\n",
    "        self.sessions.df = self.df.copy()\n",
    "        self.sessions.calculate_sessions_ranges()\n",
    "\n",
    "        if self.sessions_h1 is not None:\n",
    "            self.sessions.df = pd.merge_asof(\n",
    "                self.sessions.df.sort_values('time'),\n",
    "                self.sessions_h1.df.sort_values('time'),\n",
    "                on='time',\n",
    "                direction='backward',\n",
    "                suffixes=('', '_H1')\n",
    "            )\n",
    "\n",
    "        self.sessions.detect_session_type()\n",
    "        \n",
    "        self.sessions.detect_signals()\n",
    "\n",
    "    def merge_external_dfs(self):\n",
    "        \"\"\"\n",
    "        ≈ÅƒÖczy dane z:\n",
    "        - self.smc.df\n",
    "        - self.sessions.df\n",
    "        - sygna≈Çy z self.sessions.detect_signals()\n",
    "    \n",
    "        Pomija kolumny ju≈º obecne w self.df.\n",
    "        \"\"\"\n",
    "        base = self.df.copy()\n",
    "    \n",
    "        # --- ≈ÅƒÖczenie z self.smc.df ---\n",
    "        if hasattr(self, \"smc\") and hasattr(self.smc, \"df\"):\n",
    "            smc_df = self.smc.df.copy()\n",
    "            new_cols = [c for c in smc_df.columns if c not in base.columns]\n",
    "            if new_cols:\n",
    "                base = base.merge(smc_df[['time'] + new_cols], on='time', how='left', validate='1:1')\n",
    "    \n",
    "        # --- ≈ÅƒÖczenie z self.sessions.df ---\n",
    "        if hasattr(self, \"sessions\") and hasattr(self.sessions, \"df\"):\n",
    "            sessions_df = self.sessions.df.copy()\n",
    "            new_cols = [c for c in sessions_df.columns if c not in base.columns]\n",
    "            if new_cols:\n",
    "                base = base.merge(sessions_df[['time'] + new_cols], on='time', how='left', validate='1:1')\n",
    "\n",
    "        \n",
    "    \n",
    "        self.df = base\n",
    "\n",
    "        print(f\"Kolumny self.df: {list(self.df.columns)}\")\n",
    "\n",
    "    def calculate_levels(self, signals, close):\n",
    "\n",
    "        if not isinstance(signals, dict):\n",
    "            return None\n",
    "\n",
    "        direction = signals.get(\"direction\")\n",
    "        tag = signals.get(\"tag\")\n",
    "\n",
    "        risk = close * 0.001  # np. 0.1%\n",
    "        rr1 = 2\n",
    "        rr2 = 4\n",
    "\n",
    "        if direction == \"long\":\n",
    "            sl = close - risk\n",
    "            tp1 = close + risk * rr1\n",
    "            tp2 = close + risk * rr2\n",
    "        else:\n",
    "            sl = close + risk\n",
    "            tp1 = close - risk * rr1\n",
    "            tp2 = close - risk * rr2\n",
    "\n",
    "        return {\n",
    "            \"SL\": {\"level\": sl, \"tag\": \"auto\"},\n",
    "            \"TP1\": {\"level\": tp1, \"tag\": \"RR_1:2\"},\n",
    "            \"TP2\": {\"level\": tp2, \"tag\": \"RR_1:4\"},\n",
    "        }\n",
    "\n",
    "    def populate_entry_trend(self):\n",
    "        \"\"\"\n",
    "        Buduje sygna≈Çy wej≈õcia ≈ÇƒÖczƒÖce:\n",
    "        - kierunek sesyjny (sessions_signal)\n",
    "        - kierunek dnia (prev_day_direction)\n",
    "        - bias rynkowy (session_bias)\n",
    "        - strefy HTF/LTF (OB, FVG, Breaker)\n",
    "        \"\"\"\n",
    "\n",
    "        df = self.df.copy()\n",
    "\n",
    "        # --- üîπ 1. Agregacja stref ---\n",
    "        def merge_flags(prefix):\n",
    "            return df[f\"{prefix}_reaction_H1\"] | df[f\"{prefix}_in_zone_H1\"], \\\n",
    "                   df[f\"{prefix}_reaction\"] | df[f\"{prefix}_in_zone\"]\n",
    "\n",
    "        for side in [\"bullish\", \"bearish\"]:\n",
    "            for zone in [\"breaker\", \"fvg\", \"ob\"]:\n",
    "                df[f\"{side}_{zone}_H1\"], df[f\"{side}_{zone}\"] = merge_flags(f\"{side}_{zone}\")\n",
    "\n",
    "        # --- üîπ 2. Listy aktywnych stref ---\n",
    "        def active_cols(df, side, timeframe):\n",
    "            cols = [f\"{side}_breaker{timeframe}\", f\"{side}_ob{timeframe}\", f\"{side}_fvg{timeframe}\"]\n",
    "            return df[cols].apply(lambda x: [col.split(\"_\")[1].upper() for col in x.index if x[col]], axis=1)\n",
    "\n",
    "        df[\"htf_long_active\"] = active_cols(df, \"bullish\", \"_H1\")\n",
    "        df[\"ltf_long_active\"] = active_cols(df, \"bullish\", \"\")\n",
    "        df[\"htf_short_active\"] = active_cols(df, \"bearish\", \"_H1\")\n",
    "        df[\"ltf_short_active\"] = active_cols(df, \"bearish\", \"\")\n",
    "\n",
    "        # --- üîπ 3. Bias i kierunek dnia ---\n",
    "        df[\"prev_day_direction\"] = np.where(df[\"prev_close\"] > df[\"prev_open\"], \"bullish\",\n",
    "                                            np.where(df[\"prev_close\"] < df[\"prev_open\"], \"bearish\", None))\n",
    "        df[\"session_bias\"] = np.where(df[\"close\"] > df[\"PDH\"], \"bullish\",\n",
    "                                      np.where(df[\"close\"] < df[\"PDL\"], \"bearish\", \"neutral\"))\n",
    "\n",
    "        # --- üîπ 4. Inicjalizacja sygna≈Ç√≥w ---\n",
    "        df[\"signal_entry\"] = None\n",
    "        df[\"signal_strength\"] = 0.0\n",
    "\n",
    "        # --- üîπ 5. Maski logiczne ---\n",
    "        long_mask = (\n",
    "                (df[\"sessions_signal\"] == \"long\")\n",
    "                #(df[\"session_bias\"] == \"bullish\") &\n",
    "                #(df[\"prev_day_direction\"] == \"bullish\") &\n",
    "                #(df[\"htf_long_active\"].apply(len) > 0) &\n",
    "                #(df[\"ltf_long_active\"].apply(len) > 0)\n",
    "        )\n",
    "\n",
    "        short_mask = (\n",
    "                (df[\"sessions_signal\"] == \"short\")\n",
    "                #(df[\"session_bias\"] == \"bearish\") &\n",
    "                #(df[\"prev_day_direction\"] == \"bearish\") &\n",
    "                #(df[\"htf_short_active\"].apply(len) > 0) &\n",
    "                #(df[\"ltf_short_active\"].apply(len) > 0)\n",
    "        )\n",
    "\n",
    "        # --- üîπ 6. Generowanie sygna≈Ç√≥w + scoring ---\n",
    "        def build_entry(row, direction):\n",
    "            htf = row[f\"htf_{direction}_active\"]\n",
    "            ltf = row[f\"ltf_{direction}_active\"]\n",
    "            score = len(htf) + len(ltf)\n",
    "            tag = f\"{row['session_context']}__{row['session_bias']}__{direction.upper()}__HTF:{'-'.join(htf)}__LTF:{'-'.join(ltf)}\"\n",
    "            return {\"direction\": direction, \"tag\": tag}, score\n",
    "\n",
    "        df.loc[long_mask, [\"signal_entry\", \"signal_strength\"]] = df.loc[long_mask].apply(\n",
    "            lambda r: build_entry(r, \"long\"), axis=1, result_type=\"expand\"\n",
    "        )\n",
    "\n",
    "        df.loc[short_mask, [\"signal_entry\", \"signal_strength\"]] = df.loc[short_mask].apply(\n",
    "            lambda r: build_entry(r, \"short\"), axis=1, result_type=\"expand\"\n",
    "        )\n",
    "\n",
    "        # --- üîπ 7. Poziomy SL/TP ---\n",
    "        has_signals = df[\"signal_entry\"].apply(bool)\n",
    "        df.loc[has_signals, \"levels\"] = df.loc[has_signals].apply(\n",
    "            lambda row: self.calculate_levels(row[\"signal_entry\"], row[\"close\"]),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        print(\"here\")\n",
    "        print(df[df[\"signal_entry\"].notna()])\n",
    "\n",
    "        print(\"sessions_signal counts:\")\n",
    "        print(df[\"sessions_signal\"].value_counts(dropna=False))\n",
    "        \n",
    "        # 2. Ile wierszy spe≈Çnia podstawowe warunki (poszczeg√≥lne elementy maski)?\n",
    "        print(\"count sessions_signal == 'long':\", (df[\"sessions_signal\"] == \"long\").sum())\n",
    "        print(\"count sessions_signal == 'short':\", (df[\"sessions_signal\"] == \"short\").sum())\n",
    "        \n",
    "        # 3. Sprawd≈∫ htf/ltf ‚Äî czy rzeczywi≈õcie zwracajƒÖ listy i jakie sƒÖ ich d≈Çugo≈õci\n",
    "        print(\"htf_long_active non-empty:\", (df[\"htf_long_active\"].apply(lambda x: len(x) if isinstance(x, (list,tuple)) else 0) > 0).sum())\n",
    "        print(\"ltf_long_active non-empty:\", (df[\"ltf_long_active\"].apply(lambda x: len(x) if isinstance(x, (list,tuple)) else 0) > 0).sum())\n",
    "        print(\"htf_short_active non-empty:\", (df[\"htf_short_active\"].apply(lambda x: len(x) if isinstance(x, (list,tuple)) else 0) > 0).sum())\n",
    "        print(\"ltf_short_active non-empty:\", (df[\"ltf_short_active\"].apply(lambda x: len(x) if isinstance(x, (list,tuple)) else 0) > 0).sum())\n",
    "        \n",
    "        # 4. Sprawd≈∫ biasy i kierunek poprzedniego dnia\n",
    "        print(\"prev_day_direction unique:\", df[\"prev_day_direction\"].unique())\n",
    "        print(\"session_bias unique:\", df[\"session_bias\"].unique())\n",
    "        \n",
    "        # 5. Poka≈º pierwsze N wierszy gdzie sessions_signal nie jest NaN (je≈õli w og√≥le sƒÖ)\n",
    "        print(df[df[\"sessions_signal\"].notna()].head(10))\n",
    "\n",
    "        self.df = df\n",
    "        return df\n",
    "\n",
    "    def populate_exit_trend(self):\n",
    "\n",
    "        df = self.df\n",
    "\n",
    "        df['signal_exit'] = None\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def get_bullish_zones(self):\n",
    "        return []\n",
    "\n",
    "    def get_bearish_zones(self):\n",
    "        return []\n",
    "\n",
    "    def get_extra_values_to_plot(self):\n",
    "        return [\n",
    "            #(\"london_high\", self.sessions.df[\"london_main_high\"], \"blue\", \"dot\"),\n",
    "            #(\"london_low\", self.sessions.df[\"london_main_low\"], \"blue\", \"dot\"),\n",
    "            #(\"asia_high\", self.sessions.df[\"asia_main_high\"], \"purple\", \"dot\"),\n",
    "            #(\"asia_low\", self.sessions.df[\"asia_main_low\"], \"purple\", \"dot\"),\n",
    "            #(\"ny_high\", self.sessions.df[\"ny_main_high\"], \"orange\", \"dash\"),\n",
    "            #(\"ny_low\", self.sessions.df[\"ny_main_low\"], \"orange\", \"dash\"),\n",
    "\n",
    "            #(\"PDH\", self.sessions.df[\"PDH\"], \"blue\"),\n",
    "            #(\"PDL\", self.sessions.df[\"PDL\"], \"blue\"),\n",
    "\n",
    "            #(\"PWH\", self.sessions.df[\"PWH\"], \"yellow\"),\n",
    "            #(\"PWL\", self.sessions.df[\"PWL\"], \"yellow\"),\n",
    "        ]\n",
    "\n",
    "    def get_bullish_zones(self):\n",
    "        return [\n",
    "            #(\"Bullish IFVG H1\", self.smc.bullish_ifvg_validated_H1, \"rgba(255, 160, 122, 0.7)\"),\n",
    "            # Pomara≈Ñcz (pozostawiony bez zmian)\n",
    "            # (\"Bullish IFVG\", self.bullish_ifvg_validated, \"rgba(139, 0, 0, 1)\"),\n",
    "\n",
    "            #(\"Bullish FVG H1\", self.smc.bullish_fvg_validated_H1, \"rgba(255, 152, 0, 0.7)\"),  # Jasnoniebieski\n",
    "            # (\"Bullish FVG\", self.bullish_fvg_validated, \"rgba(255, 152, 0, 0.7)\"),             # Ciemnoniebieski\n",
    "\n",
    "            (\"Bullish OB H1\", self.smc.bullish_ob_validated_H1, \"rgba(144, 238, 144, 0.7)\"),  # Jasnozielony\n",
    "            # (\"Bullish OB\", self.bullish_ob_validated, \"rgba(0, 100, 0, 1)\"),           # Ciemnozielony\n",
    "\n",
    "            (\"Bullish Breaker H1\", self.smc.bullish_breaker_validated_H1, \"rgba(173, 216, 230, 0.7)\"),  # Jasnoniebieski\n",
    "            # (\"Bullish Breaker\", self.bullish_breaker_validated, \"rgba(0, 0, 139, 1)\"),             # Ciemnoniebieski\n",
    "\n",
    "            # (\"Bullish GAP \", self.bullish_gap_validated, \"rgba(56, 142, 60, 1)\"),\n",
    "        ]\n",
    "\n",
    "    def get_bearish_zones(self):\n",
    "        return [\n",
    "            # (\"Bearish Breaker\", self.smc.bearish_breaker_validated, \"rgba(64, 64, 64, 1)\"),      # Ciemnoszary\n",
    "             (\"Bearish Breaker H1\", self.smc.bearish_breaker_validated_H1, \"rgba(169, 169, 169, 0.7)\"),  # Jasnoszary\n",
    "\n",
    "            # (\"Bearish OB\", self.smc.bearish_ob_validated, \"rgba(139, 0, 0, 1)\"),                # Ciemnoczerwony\n",
    "             (\"Bearish OB H1\", self.smc.bearish_ob_validated_H1, \"rgba(255, 160, 122, 0.7)\"),       # Jasnoczerwony\n",
    "\n",
    "            # (\"Bearish IFVG H1\", self.smc.bearish_ifvg_validated_H1, \"rgba(139, 0, 0, 1)\"),  # Pomara≈Ñcz (pozostawiony bez zmian)\n",
    "            # (\"Bearish IFVG\", self.smc.bearish_ifvg_validated, \"rgba(255, 160, 122, 0.7)\"),\n",
    "\n",
    "            # (\"Bearish FVG\", self.smc.bearish_fvg_validated, \"rgba(0, 0, 139, 1)\"),      # Ciemnoszary\n",
    "            # (\"Bearish FVG H1\", self.smc.bearish_fvg_validated_H1, \"rgba(173, 216, 230, 0.7)\"),  # Jasnoszary\n",
    "        ]\n",
    "    \n",
    "    def bool_series(self):\n",
    "        return []\n",
    "\n",
    "\n",
    "    def run(self) -> pd.DataFrame:\n",
    "\n",
    "\n",
    "        timings = []  # Lista do przechowywania czas√≥w\n",
    "\n",
    "        def timeit(label, func):\n",
    "            start = time.time()\n",
    "            func()\n",
    "            end = time.time()\n",
    "            duration = end - start\n",
    "            timings.append((label, duration))\n",
    "            #print(f\"{label} finished in {duration:.4f} seconds\")\n",
    "\n",
    "        timeit(\"_populate_informative_indicators\", lambda: populate_informative_indicators(self))\n",
    "        timeit(\"self.populate_indicators()\", lambda: self.populate_indicators())\n",
    "        timeit(\"self.merge_external_dfs()\", lambda: self.merge_external_dfs())\n",
    "        timeit(\"self.populate_entry_trend()\", lambda: self.populate_entry_trend())\n",
    "\n",
    "        # 3Ô∏è‚É£ Zwr√≥ƒá ko≈Ñcowy DataFrame z M5 + H1 scalonymi danymi\n",
    "        print(\"\\n‚è±Ô∏è Profil czasu wykonania:\")\n",
    "        for label, duration in timings:\n",
    "            print(f\"   {label:<40} {duration:.3f}s\")\n",
    "\n",
    "\n",
    "\n",
    "        return self.sessions.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "073356c1-4d66-461d-95e6-719fc247a905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolumny self.df: ['time', 'open', 'high', 'low', 'close', 'tick_volume', 'time_H1', 'open_H1', 'high_H1', 'low_H1', 'close_H1', 'tick_volume_H1', 'spread_H1', 'real_volume_H1', 'idx_H1', 'atr_H1', 'idx', 'atr', 'ha_open', 'ha_close', 'ha_high', 'ha_low', 'min_5', 'max_5', 'cisd_bull_line', 'cisd_bear_line', 'candle_form', 'candle_bullish', 'candle_bearish', 'bullish_fvg_in_zone', 'bullish_fvg_reaction', 'bullish_fvg_in_zone_H1', 'bullish_fvg_reaction_H1', 'bullish_ob_in_zone', 'bullish_ob_reaction', 'bullish_ob_in_zone_H1', 'bullish_ob_reaction_H1', 'bullish_breaker_in_zone', 'bullish_breaker_reaction', 'bullish_breaker_in_zone_H1', 'bullish_breaker_reaction_H1', 'bullish_ifvg_in_zone', 'bullish_ifvg_reaction', 'bullish_ifvg_in_zone_H1', 'bullish_ifvg_reaction_H1', 'bearish_fvg_in_zone', 'bearish_fvg_reaction', 'bearish_fvg_in_zone_H1', 'bearish_fvg_reaction_H1', 'bearish_ob_in_zone', 'bearish_ob_reaction', 'bearish_ob_in_zone_H1', 'bearish_ob_reaction_H1', 'bearish_breaker_in_zone', 'bearish_breaker_reaction', 'bearish_breaker_in_zone_H1', 'bearish_breaker_reaction_H1', 'bearish_ifvg_in_zone', 'bearish_ifvg_reaction', 'bearish_ifvg_in_zone_H1', 'bearish_ifvg_reaction_H1', 'asian_high', 'asian_low', 'london_high', 'london_low', 'ny_high', 'ny_low', 'asia_high', 'asia_low', 'spread', 'real_volume', 'date', 'weekday', 'week', 'year', 'hour', 'monday_high', 'monday_low', 'monday', 'PDH', 'PDL', 'weekly_high', 'weekly_low', 'PWH', 'PWL', 'prev_open', 'prev_close', 'session', 'sessions_signal', 'session_context', 'signal_strength']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Poi' object has no attribute 'calculate_levels'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mbacktesting\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mplot\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m plot_trades_with_indicators\n\u001B[32m      3\u001B[39m poi = Poi(df=data, symbol=\u001B[33m\"\u001B[39m\u001B[33mEURUSD\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m df_bt = \u001B[43mpoi\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[38;5;66;03m#print(\"\\nüìä === INFORMACJE O self.smc.df ===\")\u001B[39;00m\n\u001B[32m     11\u001B[39m \u001B[38;5;66;03m#print(f\"Kszta≈Çt: {df_bt.shape}\")\u001B[39;00m\n\u001B[32m     12\u001B[39m \u001B[38;5;66;03m#print(f\"Kolumny: {list(df_bt.columns)}\")\u001B[39;00m\n\u001B[32m     13\u001B[39m \u001B[38;5;66;03m#print(\"\\nPrzyk≈Çadowe dane:\")\u001B[39;00m\n\u001B[32m     14\u001B[39m \u001B[38;5;66;03m#print(df_bt.head(5))\u001B[39;00m\n\u001B[32m     17\u001B[39m plot_trades_with_indicators(\n\u001B[32m     18\u001B[39m     df_bt,\n\u001B[32m     19\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mEURUSD\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     23\u001B[39m     bool_series=poi.bool_series(),\n\u001B[32m     24\u001B[39m                 )\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 481\u001B[39m, in \u001B[36mPoi.run\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    479\u001B[39m timeit(\u001B[33m\"\u001B[39m\u001B[33mself.populate_indicators()\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mlambda\u001B[39;00m: \u001B[38;5;28mself\u001B[39m.populate_indicators())\n\u001B[32m    480\u001B[39m timeit(\u001B[33m\"\u001B[39m\u001B[33mself.merge_external_dfs()\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mlambda\u001B[39;00m: \u001B[38;5;28mself\u001B[39m.merge_external_dfs())\n\u001B[32m--> \u001B[39m\u001B[32m481\u001B[39m \u001B[43mtimeit\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mself.populate_entry_trend()\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpopulate_entry_trend\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    483\u001B[39m \u001B[38;5;66;03m# 3Ô∏è‚É£ Zwr√≥ƒá ko≈Ñcowy DataFrame z M5 + H1 scalonymi danymi\u001B[39;00m\n\u001B[32m    484\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m‚è±Ô∏è Profil czasu wykonania:\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 472\u001B[39m, in \u001B[36mPoi.run.<locals>.timeit\u001B[39m\u001B[34m(label, func)\u001B[39m\n\u001B[32m    470\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mtimeit\u001B[39m(label, func):\n\u001B[32m    471\u001B[39m     start = time.time()\n\u001B[32m--> \u001B[39m\u001B[32m472\u001B[39m     \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    473\u001B[39m     end = time.time()\n\u001B[32m    474\u001B[39m     duration = end - start\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 481\u001B[39m, in \u001B[36mPoi.run.<locals>.<lambda>\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    479\u001B[39m timeit(\u001B[33m\"\u001B[39m\u001B[33mself.populate_indicators()\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mlambda\u001B[39;00m: \u001B[38;5;28mself\u001B[39m.populate_indicators())\n\u001B[32m    480\u001B[39m timeit(\u001B[33m\"\u001B[39m\u001B[33mself.merge_external_dfs()\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mlambda\u001B[39;00m: \u001B[38;5;28mself\u001B[39m.merge_external_dfs())\n\u001B[32m--> \u001B[39m\u001B[32m481\u001B[39m timeit(\u001B[33m\"\u001B[39m\u001B[33mself.populate_entry_trend()\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mlambda\u001B[39;00m: \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpopulate_entry_trend\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m    483\u001B[39m \u001B[38;5;66;03m# 3Ô∏è‚É£ Zwr√≥ƒá ko≈Ñcowy DataFrame z M5 + H1 scalonymi danymi\u001B[39;00m\n\u001B[32m    484\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m‚è±Ô∏è Profil czasu wykonania:\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 365\u001B[39m, in \u001B[36mPoi.populate_entry_trend\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    363\u001B[39m \u001B[38;5;66;03m# --- üîπ 7. Poziomy SL/TP ---\u001B[39;00m\n\u001B[32m    364\u001B[39m has_signals = df[\u001B[33m\"\u001B[39m\u001B[33msignal_entry\u001B[39m\u001B[33m\"\u001B[39m].apply(\u001B[38;5;28mbool\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m365\u001B[39m df.loc[has_signals, \u001B[33m\"\u001B[39m\u001B[33mlevels\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[43mdf\u001B[49m\u001B[43m.\u001B[49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mhas_signals\u001B[49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    366\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrow\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcalculate_levels\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43msignal_entry\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mclose\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    367\u001B[39m \u001B[43m    \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\n\u001B[32m    368\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    370\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mhere\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    371\u001B[39m \u001B[38;5;28mprint\u001B[39m(df[df[\u001B[33m\"\u001B[39m\u001B[33msignal_entry\u001B[39m\u001B[33m\"\u001B[39m].notna()])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\PandasAlgoTrader\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:10401\u001B[39m, in \u001B[36mDataFrame.apply\u001B[39m\u001B[34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001B[39m\n\u001B[32m  10387\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcore\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mapply\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m frame_apply\n\u001B[32m  10389\u001B[39m op = frame_apply(\n\u001B[32m  10390\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m  10391\u001B[39m     func=func,\n\u001B[32m   (...)\u001B[39m\u001B[32m  10399\u001B[39m     kwargs=kwargs,\n\u001B[32m  10400\u001B[39m )\n\u001B[32m> \u001B[39m\u001B[32m10401\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m.__finalize__(\u001B[38;5;28mself\u001B[39m, method=\u001B[33m\"\u001B[39m\u001B[33mapply\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\PandasAlgoTrader\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001B[39m, in \u001B[36mFrameApply.apply\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    913\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.raw:\n\u001B[32m    914\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.apply_raw(engine=\u001B[38;5;28mself\u001B[39m.engine, engine_kwargs=\u001B[38;5;28mself\u001B[39m.engine_kwargs)\n\u001B[32m--> \u001B[39m\u001B[32m916\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\PandasAlgoTrader\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001B[39m, in \u001B[36mFrameApply.apply_standard\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1061\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mapply_standard\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m   1062\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.engine == \u001B[33m\"\u001B[39m\u001B[33mpython\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m-> \u001B[39m\u001B[32m1063\u001B[39m         results, res_index = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mapply_series_generator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1064\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1065\u001B[39m         results, res_index = \u001B[38;5;28mself\u001B[39m.apply_series_numba()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\PandasAlgoTrader\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001B[39m, in \u001B[36mFrameApply.apply_series_generator\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1078\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m option_context(\u001B[33m\"\u001B[39m\u001B[33mmode.chained_assignment\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m   1079\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m i, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(series_gen):\n\u001B[32m   1080\u001B[39m         \u001B[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1081\u001B[39m         results[i] = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1082\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(results[i], ABCSeries):\n\u001B[32m   1083\u001B[39m             \u001B[38;5;66;03m# If we have a view on v, we need to make a copy because\u001B[39;00m\n\u001B[32m   1084\u001B[39m             \u001B[38;5;66;03m#  series_generator will swap out the underlying data\u001B[39;00m\n\u001B[32m   1085\u001B[39m             results[i] = results[i].copy(deep=\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 366\u001B[39m, in \u001B[36mPoi.populate_entry_trend.<locals>.<lambda>\u001B[39m\u001B[34m(row)\u001B[39m\n\u001B[32m    363\u001B[39m \u001B[38;5;66;03m# --- üîπ 7. Poziomy SL/TP ---\u001B[39;00m\n\u001B[32m    364\u001B[39m has_signals = df[\u001B[33m\"\u001B[39m\u001B[33msignal_entry\u001B[39m\u001B[33m\"\u001B[39m].apply(\u001B[38;5;28mbool\u001B[39m)\n\u001B[32m    365\u001B[39m df.loc[has_signals, \u001B[33m\"\u001B[39m\u001B[33mlevels\u001B[39m\u001B[33m\"\u001B[39m] = df.loc[has_signals].apply(\n\u001B[32m--> \u001B[39m\u001B[32m366\u001B[39m     \u001B[38;5;28;01mlambda\u001B[39;00m row: \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcalculate_levels\u001B[49m(row[\u001B[33m\"\u001B[39m\u001B[33msignal_entry\u001B[39m\u001B[33m\"\u001B[39m], row[\u001B[33m\"\u001B[39m\u001B[33mclose\u001B[39m\u001B[33m\"\u001B[39m]),\n\u001B[32m    367\u001B[39m     axis=\u001B[32m1\u001B[39m\n\u001B[32m    368\u001B[39m )\n\u001B[32m    370\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mhere\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    371\u001B[39m \u001B[38;5;28mprint\u001B[39m(df[df[\u001B[33m\"\u001B[39m\u001B[33msignal_entry\u001B[39m\u001B[33m\"\u001B[39m].notna()])\n",
      "\u001B[31mAttributeError\u001B[39m: 'Poi' object has no attribute 'calculate_levels'"
     ]
    }
   ],
   "source": [
    "from backtesting.plot import plot_trades_with_indicators\n",
    "\n",
    "poi = Poi(df=data, symbol=\"EURUSD\")\n",
    "\n",
    "\n",
    "df_bt = poi.run()\n",
    "\n",
    "\n",
    "\n",
    "#print(\"\\nüìä === INFORMACJE O self.smc.df ===\")\n",
    "#print(f\"Kszta≈Çt: {df_bt.shape}\")\n",
    "#print(f\"Kolumny: {list(df_bt.columns)}\")\n",
    "#print(\"\\nPrzyk≈Çadowe dane:\")\n",
    "#print(df_bt.head(5))\n",
    "\n",
    "         \n",
    "plot_trades_with_indicators(\n",
    "    df_bt,\n",
    "    \"EURUSD\",\n",
    "    bullish_zones=poi.get_bullish_zones(),\n",
    "    bearish_zones=poi.get_bearish_zones(),\n",
    "    extra_series=poi.get_extra_values_to_plot(),\n",
    "    bool_series=poi.bool_series(),\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e65a6e0-fd66-4156-b94c-c87703fbaedf",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a9365c-6f35-4396-bc53-cee2fe9b7c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4ef071-3988-4b8f-8a8e-b687330a2adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a04224-565e-4d13-ba59-767477eb4817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dc5ef8-3e9d-42c2-8bee-638d4bc2665b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
